\section{Methodik}
\label{sec:methodik}

Dieses Kapitel beschreibt Datenbasis, Vorverarbeitung und experimentelles Setup zur Entwicklung und Evaluation der in dieser Arbeit vorgestellten CrossBERT-Architektur.

\subsection{Datenbasis und Vorverarbeitung}
\label{sec:data_basis}

Es wird ein hybrider Ansatz verfolgt: proprietäre Echtdaten aus der Versicherungswirtschaft werden mit öffentlichen Benchmarks kombiniert. Alle Datensätze werden über eine einheitliche Pipeline (\texttt{LightningDataModule}) in konsistente Tensor-Repräsentationen überführt, inklusive Splitting, tabellarischer Transformationen und Texttokenisierung.

\subsubsection{Datenbasis}
Der primäre Datensatz stammt aus einem deutschen Versicherungsunternehmen und wurde für die Identifikation von Regresspotenzialen kuratiert. Es handelt sich um ein Multi-Class-Setting mit den Zielklassen \textit{Kein Regress} (0), \textit{Regress} (1) und \textit{Versicherungsschutzentzug} (2). Er kombiniert unstrukturierte Schadenbeschreibungen mit tabellarischen Metadaten (Tabelle \ref{tab:sample_case} zeigt einen exemplarischen Datenpunkt). Methodisch relevant sind ein \textit{Selection Bias} (Labels entstehen historisch nur für manuell geprüfte Fälle) sowie ein \textit{Missing Label Problem}. Für ungelabelte Fälle wird initial Label 0 angenommen und die dadurch entstehenden Unsicherheiten werden als potenziell verrauschte Labels berücksichtigt.

\begin{table}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \caption{Exemplarischer Datensatz der internen Regressdatenbasis (anonymisiert).}
    \label{tab:sample_case}
    \begin{tabular}{@{}lp{0.75\textwidth}@{}}
        \hline
        \textbf{Metadaten} & ID: 68443XXXX, Label: 1 (Regress), Status: Validiert (True)\\
        \hline
        \textbf{Textmodalität} & \textit{Schadenhergang:} VN: Kreuzung: Vn hatte grünen Pfeil der aufgeleuchtet sei. Es kam zur Kollision Vorgang strittig. \textit{Dokumente:} ausführliche HSA, strittige Ampel, PUM, EA-Geb-re io. \textit{Notizen:} PWS empfiehlt Beauftragung eines SV; ADAC bereits auf dem Weg; wst wartet auf fg... \\
        \hline
        \textbf{Tabellarische Merkmale} & \texttt{log\_zlg\_fzg}: 9,839, \texttt{kh\_other\_partially\_paid}: 1, \texttt{untersparte}: KF.VK, \texttt{risikoschluessel}: UNF, \texttt{svorg\_schadenursache}: Unfall ein weiteres Kfz, \texttt{had\_ever\_erinnerungsregress}: 1 \\
        \hline
    \end{tabular}
\end{table}

Zur externen Validierung werden zwei Kaggle-Benchmarks genutzt:
\begin{enumerate}
    \item \textbf{Women's E-Commerce Clothing Reviews} \cite{KaggleEcommerce}: Binäre Sentiment-Klassifikation mit Text und Metadaten.
    \item \textbf{PetFinder.my Adoption Prediction} \cite{KagglePetfinder}: Multi-Class-Klassifikation mit Beschreibungen und Metadaten.
\end{enumerate}
Damit wird die Übertragbarkeit der Architektur außerhalb der Versicherungsdomäne überprüft.

\subsubsection{Datenvorverarbeitung}
Die Vorverarbeitung trennt strikt Trainings-, Validierungs- und Testdaten, um Data Leakage zu vermeiden. Das Splitting erfolgt stratifiziert (bei Multi-Class) und nutzt (sofern verfügbar) feste Test-Indizes. Zusätzlich wird aus dem Trainingssplit ein Validierungsanteil (\texttt{validation\_\allowbreak fraction}) abgeleitet. Optional wird die Klassenverteilung im Training über Undersampling der Majoritätsklasse auf ein vorgegebenes Verhältnis $N(0)/N(1)$ (\texttt{train\_\allowbreak imbalance\_\allowbreak 0\_\allowbreak to\_\allowbreak 1}) eingestellt. Die zentralen Schritte sind:
\begin{itemize}
    \item \textbf{Tabellarische Daten:} One-Hot-Encoding für kategoriale Merkmale (fehlende Werte als Kategorie \texttt{None}, unbekannte Kategorien werden ignoriert); Min-Max-Skalierung numerischer Variablen auf $[0,1]$. Die Encoder/Scaler werden ausschließlich auf Trainingsdaten trainiert (\textit{fit}) und auf Validierung/Test angewandt (\textit{transform}).
    \item \textbf{Textdaten:} Tokenisierung mit \texttt{bert\allowbreak-base\allowbreak-uncased} (inkl.\ \texttt{[CLS]} und \texttt{[SEP]}); Padding/Truncation auf die modellabhängige maximale Kontextlänge (für BERT: 512 Tokens).
    \item \textbf{Splitting und Balancing:} Stratified Split unter Beibehaltung der Klassenverteilung (insbesondere relevant bei Multi-Class, z.\,B. PetFinder). Im Training wird optional ein Random Undersampling der Majoritätsklasse eingesetzt, gesteuert über \texttt{train\_\allowbreak imbalance\_\allowbreak 0\_\allowbreak to\_\allowbreak 1}.
\end{itemize}

\newpage
\subsection{Baseline-Modelle}
\label{sec:baselines}

Um den Mehrwert der entwickelten CrossBERT-Architektur präzise zu quantifizieren, erfolgt ein Vergleich mit zwei bestehenden multimodalen Modellen für die Fusion von tabellarischen Daten und Textdaten: SumBERT (Early Fusion) und ConcatBERT (Late Fusion). Der vollständige Quellcode beider Implementierungen befindet sich in Anhang \ref{app:source_code_baselines}.

\subsubsection{SumBERT (Early Fusion)}
SumBERT realisiert eine frühe Fusion, bei der die Tabelleninformationen bereits vor dem Encoder in den Modellkontext integriert werden. Hierfür werden die normalisierten und kodierten Tabellendaten zunächst mittels einer linearen Projektionsschicht (\texttt{nn.Linear}) in den Vektorraum des Sprachmodells projiziert ($H=768$). Dieser projizierte Vektor wird anschließend elementweise zum Embedding des \texttt{[CLS]}-Tokens addiert, noch bevor die Sequenz den ersten Transformer-Layer erreicht (siehe Abbildung \ref{fig:sumbert}).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{Bilder/SumBERT_Modellarchitektur.png}
    \caption{Architektur von SumBERT: Addition der Tabellen-Repräsentation zum CLS-Token-Embedding vor dem Encoder.}
    \label{fig:sumbert}
\end{figure}

Formal lässt sich die Berechnung des fusionierten Eingabevektors wie folgt beschreiben:
\begin{equation}
    E_{\text{fused}}^{[CLS]} = E_{\text{text}}^{[CLS]} + \text{MLP}_{\text{tab}}(X_{\text{tab}})
\end{equation}

Durch diese additive Verknüpfung am Eingang fungiert das \texttt{[CLS]}-Token als globaler Träger multimodaler Informationen, die anschließend über den Self-Attention-Mechanismus im Transformer-Encoder in alle tieferen Schichten des Modells propagiert werden.

\newpage
\subsubsection{ConcatBERT (Late Fusion)}
Im Gegensatz dazu verfolgt ConcatBERT einen Ansatz der späten Fusion. Text- und Tabellendaten werden hierbei zunächst separat verarbeitet. Der Text durchläuft den vollständigen BERT-Encoder, um eine kontextualisierte Repräsentation des \texttt{[CLS]}-Tokens zu generieren. Erst im Anschluss an den Encoding-Prozess wird dieser Vektor mit den rohen bzw. leicht vorverarbeiteten Tabellen-Features konkateniert (siehe Abbildung \ref{fig:concatbert}).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{Bilder/ConcatBERT_Modellarchitektur.png}
    \caption{Architektur von ConcatBERT: Konkatenation der Tabellen-Features mit dem Output des BERT-Encoders.}
    \label{fig:concatbert}
\end{figure}

Der resultierende Vektor dient als Eingabe für den Klassifikations-Head:
\begin{equation}
    h_{\text{fusion}} = [ \text{BERT}(E_{\text{text}})_{[CLS]} \parallel X_{\text{tab}} ]
\end{equation}

Diese Architektur ist rechnerisch effizient und leicht zu implementieren, verhindert jedoch eine tiefe Interaktion zwischen den Modalitäten während der Feature-Extraktion, da die Tabellendaten den Self-Attention-Mechanismus des Transformers nicht durchlaufen.

\newpage
\subsection{CrossBERT-Architektur}
\label{sec:crossbert_architecture}

Die CrossBERT-Architektur erweitert einen \gls{bert}-Klassifikator um Cross-Attention zwischen Text und Tabellendaten, um eine kontextabhängige, tiefe Interaktion der Modalitäten zu ermöglichen (vgl. Abschnitt \ref{sec:transformer_attention}). Im Unterschied zu SumBERT und ConcatBERT (Abschnitt \ref{sec:baselines}) wird die tabellarische Modalität nicht als statischer Zusatzvektor behandelt, sondern als kurze Token-Sequenz in denselben Hidden-Space projiziert und vom Text gezielt \enquote{abgefragt}. Der vollständige Quellcode ist in Anhang \ref{app:source_code_crossbert} (Listing \ref{lst:crossbert_code}) dokumentiert.

\subsubsection{Architekturüberblick}
Abbildung \ref{fig:crossbert_architecture} zeigt den Gesamtaufbau. Text wird mit \texttt{deepset/gbert-base} in Embeddings überführt und durch den Encoder kontextualisiert ($H=768$). Tabellarische Features werden parallel durch einen \textit{TabularTokenizer} in $N$ Tab Tokens kodiert. Optional werden ein oder zwei Cross-Attention-Blöcke eingesetzt, die ausschließlich den \texttt{[CLS]}-Token mit Tab Tokens fusionieren: (i) \textit{early} vor dem Encoder (Eingangs-Embeddings) und/oder (ii) \textit{late} nach dem Encoder (finaler \texttt{[CLS]}-State). Der Klassifikationskopf arbeitet anschließend auf dem fusionierten \texttt{[CLS]}-Vektor.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{Bilder/CrossBERT_Modellarchitektur.png}
    \caption{Architektur von CrossBERT mit optionaler Early- und Late-Cross-Attention über Tab Tokens.}
    \label{fig:crossbert_architecture}
\end{figure}

\subsubsection{TabularTokenizer}
Die tabellarische Eingabe liegt nach der Vorverarbeitung als Vektor $X_{\text{tab}} \in \mathbb{R}^{B \times F}$ vor (normalisierte numerische Variablen und One-Hot-kodierte kategoriale Merkmale). Analog zur in Abschnitt \ref{sec:tab_representation} beschriebenen globalen Projektion werden daraus $N$ latente Tokens $E_{\text{tab}} \in \mathbb{R}^{B \times N \times H}$ erzeugt (Abbildung \ref{fig:tabular_tokenizer}):
\begin{equation}
    E_{\text{tab}} = [\mathbf{e}_1,\dots,\mathbf{e}_N], \quad \mathbf{e}_i \in \mathbb{R}^{B \times H}
\end{equation}
Praktisch wird dies durch $N$ gelernte parallele MLP-Projektionsköpfe realisiert, die denselben Feature-Vektor in unterschiedliche Teilrepräsentationen abbilden. Intuitiv kodiert jeder Tab Token einen anderen Blick auf dieselben Tabulardaten und macht so eine gezielte Interaktion mit dem Text über Cross-Attention möglich. Die Tokenanzahl $N$ ist ein Hyperparameter (\texttt{num\_\allowbreak tab\_\allowbreak token}); die Wahl eines kleinen $N$ entkoppelt die Sequenzlänge von $F$ und hält die Fusion rechnerisch effizient.

\subsubsection{Cross-Attention-Block}
Die Fusion erfolgt über Cross-Attention, bei der der \texttt{[CLS]}-Token als Query dient und Tab Tokens als Keys/Values (vgl. Abschnitt \ref{sec:transformer_attention}). Für $\mathbf{c} \in \mathbb{R}^{B \times 1 \times H}$ gilt:
\begin{equation}
    Q = \mathbf{c} W_Q,\quad K = E_{\text{tab}} W_K,\quad V = E_{\text{tab}} W_V
\end{equation}
Die resultierenden Attention-Gewichte steuern, welche Teile der Tabulardaten für die aktuelle Texteingabe relevant sind. Dadurch wird die \texttt{[CLS]}-Repräsentation nach der Attention um tabellarischen Kontext angereichert. CrossBERT verwendet Multi-Head Attention und ergänzt diese um Residualpfade sowie ein Feed-Forward-Netzwerk (Abbildung \ref{fig:cross_attention_block}). Optional kann eine Tab-Maske genutzt werden, um einzelne Tab Tokens in der Attention auszublenden.

\begin{figure}[H]
    \centering
    \hfill
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Bilder/TabularTokenizer_Diagram.png}
        \caption{TabularTokenizer}
        \label{fig:tabular_tokenizer}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Bilder/CrossAttentionBlock_Diagram.png}
        \caption{Cross-Attention-Block}
        \label{fig:cross_attention_block}
    \end{subfigure}
    \hfill
    \caption{Komponenten der CrossBERT-Architektur: Links die Projektion der Features in Tab Tokens, rechts deren Integration via Cross-Attention.}
    \label{fig:crossbert_components}
\end{figure}

\subsubsection{Fusionsvarianten: Early, Late und Hybrid}
Die Positionierung des Cross-Attention-Blocks operationalisiert die in den theoretischen Grundlagen diskutierten Fusionszeitpunkte:
\begin{itemize}
    \item \textbf{Early Fusion:} Cross-Attention wird auf den \texttt{[CLS]}-Embedding-Vektor vor dem Encoder angewandt, sodass tabellarische Information die gesamte nachfolgende Kontextualisierung beeinflussen kann.
    \item \textbf{Late Fusion:} Cross-Attention wird erst auf den finalen Encoder-\texttt{[CLS]}-State angewandt, wodurch tabellarische Information als kontextabhängige Nachschärfung der Dokumentrepräsentation integriert wird.
    \item \textbf{Hybrid Fusion:} Early und Late Fusion werden kombiniert, um sowohl die Encoder-Features als auch die finale Entscheidungsschicht mit Tabellensignalen zu versorgen.
\end{itemize}

Falls keine tabellarischen Features vorliegen oder Cross-Attention deaktiviert ist, verhält sich CrossBERT identisch zu einem unimodalen \gls{bert}-Klassifikator und bleibt damit direkt vergleichbar.

\newpage
\subsection{Trainings-Setup und Evaluationsmetriken}
\label{sec:training_setup}

Für eine wissenschaftliche Vergleichbarkeit werden alle Experimente unter identischen Rahmenbedingungen durchgeführt. Die Pipeline ist über eine zentralisierte Konfiguration parametrisiert und setzt alle relevanten Hyperparameter (Modell, Optimierung, Splitting, Callbacks) konsistent über Baselines und CrossBERT hinweg.

\paragraph{Modell und Lernstrategie.}
Als Textencoder wird \texttt{deepset/\allowbreak gbert-base} verwendet \cite{Chan2020GBERT}. GBERT ist ein vortrainiertes deutsches Sprachmodell auf Basis von BERT \cite{Devlin2019} und dient als Initialisierung für das end-to-end Fine-Tuning im jeweiligen Klassifikations-Setup. Die Klassifikation erfolgt überwacht mit Cross-Entropy-Loss. Die Architekturvariante (Baseline vs.\ CrossBERT) beeinflusst dabei ausschließlich die Art der multimodalen Fusion (vgl.\ Abschnitt \ref{sec:crossbert_architecture}).

\paragraph{Optimierung und Trainingsprotokoll.}
Die zentralen Trainingshyperparameter sind in Tabelle \ref{tab:training_hparams} zusammengefasst. Zur Stabilisierung des Fine-Tunings wird eine Lernratenstrategie aus linearem Warmup und anschließendem Cosine Scheduling eingesetzt. Das Early Stopping überwacht \texttt{val/average\_\allowbreak precision}. Die Validierung wird in festen Intervallen innerhalb einer Epoche ausgeführt (\texttt{val\_\allowbreak check\_\allowbreak interval}=500). 
Für die \emph{Gating}-Ablation nach Flamingo (\cite{Alayrac2022}, siehe Abschnitt \ref{sec:ablations}) werden ausschließlich dafür zusätzlich (i) der \gls{bert}-Encoder für die ersten zwei Epochen eingefroren (\texttt{freeze\_bert\_epochs}=2), (ii) die Gating-Parameter (\texttt{alpha\_}) mit einer um den Faktor 5 erhöhten Lernrate ohne Weight Decay optimiert (\texttt{lr\_alpha\_multiplier}=5{,}0) und (iii) die Epochen-Grenzen auf min/max 2/6 gesetzt.

\begin{table}[H]
    \centering
    \small
    \caption{Zentrale Trainingshyperparameter (Basiskonfiguration ohne Gating).}
    \label{tab:training_hparams}
    \begin{tabular}{@{}ll@{}}
        \hline
        \textbf{Parameter} & \textbf{Wert} \\
        \hline
        Seed & 777 \\
        Optimizer & AdamW \\
        Lernrate & $1\cdot 10^{-5}$ \\
        LR-Scheduler & Linear Warmup (0{,}1) + Cosine \\
        Batchgröße (Train / Eval) & 64 / 128 \\
        Epochen (min / max) & 1 / 4 \\
        Early Stopping & Patience 5, Monitor \texttt{val/average\_\allowbreak precision} \\
        Validierungsanteil & \texttt{validation\_\allowbreak fraction}=0{,}2 \\
        \hline
\end{tabular}
\end{table}

\paragraph{Validierung, Hardware und Mixed Precision.}
Die Validierung erfolgt über einen festen Train/Val/Test-Split gemäß der Datenpipeline (vgl.\ Abschnitt \ref{sec:data_basis}). Alle Experimente werden auf einer einzelnen NVIDIA Tesla V100-PCIE-32GB ausgeführt. Zur Beschleunigung wird Mixed Precision eingesetzt, wodurch sich Rechenzeit und Speicherbedarf bei vergleichbarer Modellqualität reduzieren lassen.

\paragraph{Evaluationsmetriken.}
Als Kernmetriken werden Average Precision (AP) und AUC-ROC berichtet. AP ist für unausgeglichene Klassenverteilungen besonders aussagekräftig, da sie die Precision-Recall-Kurve über alle Entscheidungsschwellen zusammenfasst. AUC-ROC misst die Fähigkeit des Modells, positive gegenüber negativen Beispielen korrekt zu ranken, unabhängig von einem festen Schwellenwert. In Multi-Class-Settings werden beide Kennzahlen one-vs-rest pro Klasse berechnet. Zusätzlich werden die Klassen binarisiert (positiv vs.\ Klasse 0), um eine konsistente Vergleichbarkeit über Datensätze hinweg zu gewährleisten.


\newpage
\subsection{Ablationsstudien}
\label{sec:ablations}

Um den Einfluss einzelner Architektur-Entscheidungen systematisch zu verstehen, werden gezielte Ablationsstudien durchgeführt.

\begin{table}[h]
\centering
\caption{Übersicht der geplanten Ablationsstudien}
\label{tab:ablations_overview}
\begin{tabular}{|l|p{0.36\textwidth}|p{0.44\textwidth}|}
\hline
\textbf{Ablation} & \textbf{Variable (Wertebereich)} & \textbf{Ziel} \\ \hline
Cross-Attention & Position: Early / Late / Hybrid & Einfluss des Fusionsorts (vor/nach Encoder vs.\ kombiniert) \\ \hline
Tab Tokens & $n_{\text{tab}}$ (Hybrid): 0 / 1 / 2 / 4 / 8 / 16 & Quantitativ prüfen, wie stark $n_{\text{tab}}$ die Leistung von CrossBERT (Hybrid) beeinflusst \\ \hline
Gating Layer & Flamingo-style \cite{Alayrac2022}: Mit / Ohne & Adaptive Gewichtung Text$\leftrightarrow$Tab für stabilere Scores und ökonomische Kennzahlen \\ \hline
Tokenizer & TabTokenizer: V1 /\ V2 (per-Feature-Tokenisierung) & Prüfen, ob feinere Tokenisierung Fusion und Interpretierbarkeit verbessert \\ \hline
\end{tabular}
\end{table}

Im Fokus stehen (i) die Positionierung der Cross-Attention (Early/Late/Hybrid), (ii) die Sensitivität gegenüber der Anzahl der Tab Tokens $n_{\text{tab}}$ im Hybrid-Setup, (iii) ein Gating-Mechanismus nach Flamingo zur stabileren Fusion sowie (iv) ein \textit{TabTokenizer V2} mit per-Feature-Tokenisierung zur potenziell besseren Interpretierbarkeit. Für die \emph{Gating}-Ablation wurden die im Flamingo-Ansatz beschriebenen trainingsseitigen Anpassungen gezielt übernommen (Encoder-Freezing und erhöhte Lernrate für die Gate-Parameter; vgl.\ Abschnitt \ref{sec:training_setup}), da andernfalls die zusätzlichen Freiheitsgrade des Gates im Fine-Tuning empirisch instabil waren.
